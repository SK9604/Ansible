# 44.

### **회사에서 Amazon EC2를 사용하여 빅 데이터 분석 워크로드를 실행하고 있습니다. 이러한** 가변 워크로드는 매일 밤 실행되므로 다음 날 업무가 시작될 때 완료해야 합니다. 솔루션 아키텍트는 가장 비용 효율적인 솔루션을 설계하는 일을 맡았습니다. 어떤 솔루션이 이 작업을 수행합니까?

**A. 스팟 집합fleet**

**B. 스팟 인스턴스**

**C. 예약 인스턴스**

**D. 온 디맨드 인스턴스**

# 119.

### **회사에는 퍼블릭 웹 사이트에 액세스하여 패치 및 업데이트를 다운로드 해야하는 프라이빗 서브넷에서 실행되는 Amazon EC2 인스턴스가 있습니다. 회사는 외부 웹 사이트가 EC2 인스턴스 IP 주소를 보거나 연결을 시작하지 않기를 원합니다. 솔루션 아키텍트는 어떻게 이 목표를 달성 할 수 있습니까?**

**A. 프라이빗 서브넷과 퍼블릭 사이트가 배포 된 네트워크간에 사이트 간 VPN 연결 만들기**

**B. 퍼블릭 서브넷에서 NAT 게이트웨이 생성합니다. 프라이빗 서브넷에서 NAT 게이트웨이를 통해 아웃 바운드 트래픽을 라우팅합니다.**

**C. 배포 된 EC2 인스턴스가 퍼블릭 웹 사이트의 IP 주소 범위에서만 액세스를 허용하는 프라이빗 서브넷에 대한 네트워크 ACL을 만듭니다.**

**D. 공개 웹 사이트의 IP 주소 범위에서만 연결을 허용하는 보안 그룹을 만듭니다. 보안 그룹을 EC2 인스턴스에 연결하십시오.** Answer: B

# 207.

### **회사에는 VPC의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 애플리케이션 중 하나는 객체를 저장하고 읽기 위해 Amazon S3 API를 호출해야 합니다. 회사의 보안 정책은 응용 프로그램의 인터넷으로 바인딩된(internet-bound) 트래픽을 제한합니다.(인터넷으로 연결된 모든 트래픽 제한?) 이러한 요구 사항을 충족하고 보안을 유지하는 조치는 무엇입니까?**

**A. S3 인터페이스 엔드 포인트를 구성하십시오.**

**B. S3 게이트웨이 엔드 포인트를 구성하십시오.**

**C. 프라이빗 서브넷에서 S3 버킷을 만듭니다.**

**D. EC2 인스턴스와 동일한 리전에서 S3 버킷을 생성합니다.**

# QUESTION NO: 368

### 회사는 최근 AWS Direct Connect를 사용하여 하이브리드 클라우드 연결을 구현했으며 데이터를 Amazon S3로 마이그레이션하고 있습니다. 이 회사는 온 프레미스 스토리지 시스템과 AWS 스토리지 서비스 간의 데이터 복제를 자동화하고 가속화 하는 완전 관리 형 솔루션을 찾고 있습니다.
솔루션 설계자가 데이터를 비공개로 유지하기 위해 어떤 솔루션을 권장해야 합니까?

**A. 온 프레미스 환경에 AWS DataSync 에이전트 배포 데이터를 복제하고 AWS 서비스 엔드 포인트와 연결하도록 동기화 작업을 구성하십시오.
B. 온 프레미스 환경을 위한 AWS DataSync 에이전트를 배포하십시오. 특정 시점 스냅 샷을 AWS에 복제하도록 배치 작업을 예약합니다.
C. 온 프레미스 환경을 위한 AWS Storage Gateway 볼륨 게이트웨이 배포 데이터를 로컬에 저장하고 특정 시점 스냅 샷을 AWS에 비동기식으로 백업하도록 구성합니다.
D. 온 프레미스 환경을 위한 AWS Storage Gateway 파일 게이트웨이를 배포합니다. 로컬로 데이터를 저장하고 포인트인 라임 스냅 샷을 AWS에 비동기식으로 백업하도록 구성합니다.**

# QUESTION NO: 380

### 회사의 웹 애플리케이션은 여러 Linux Amazon EC2 인스턴스를 사용하고 Amazon EBS 볼륨에 데이터를 저장하고 있습니다. 이 회사는 장애 발생시 애플리케이션의 탄력성을 높이고 원자성, 일관성, 격리 및 내구성 (ACID)을 준수하는 스토리지를 제공하는 솔루션을 찾고 있습니다.
솔루션 아키텍트는 이러한 요구 사항을 충족시키기 위해 무엇을 해야 합니까?

**A. 각 가용 영역의 EC2 인스턴스에서 애플리케이션을 시작하십시오. 각 EC2 인스턴스에 EBS 볼륨을 연결하십시오.**

**B. 여러 가용 영역에서 Auto Scaling 그룹으로 Application Load Balancer 생성 각 EC2 인스턴스에 인스턴스 스토어 탑재
C. 여러 가용 영역에서 Auto Scaling 그룹으로 Application Load Balancer를 생성하십시오. Amazon EFS에 데이터를 저장하고 각 인스턴스에 대상을 마운트 하십시오.
D. Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)를 사용하여 여러 가용 영역에서 Auto Scaling 그룹으로 Application Load Balancer 생성 데이터 저장**

# QUESTION NO: 386?

### 회사에는 Amazon RDS MySQL DB 인스턴스에서 정보를 검색하는 자격 증명이 내장 된 사용자 지정 애플리케이션이 있습니다. 경영진은 최소한의 프로그래밍 노력으로 응용 프로그램의 보안을 강화해야 한다고 말합니다. 솔루션 아키텍트는 이러한 요구 사항을 충족시키기 위해 무엇을 해야 합니까?

**A. AWS KMS (AWS Key Management Service) 고객 마스터 키 (CMK)를 사용하여 키를 생성하십시오. AWS KMS 자동 키 순환 활성화에서 데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성하십시오.**

**B. 애플리케이션 사용자의 RDS for MySQL 데이터베이스에서 자격 증명을 생성하고 자격증명을 AWS Secrets Manager에 저장합니다. Secrets Manager에서 데이터베이스 자격 증명을 로드하도록 응용 프로그램을 구성하십시오. Secret Manager에서 자격 증명을 회전시키는 AWS Lambda 함수를 생성하십시오.**

**C. 애플리케이션 사용자의 RDS for MySQL 데이터베이스에서 자격 증명을 생성하고 자격 증명을 AWS Secrets Manager에 저장합니다. Secrets Manager에서 데이터베이스 자격 증명을 로드하도록 응용 프로그램을 구성하십시오. Secrets Manager를 사용하여 RDS for MySQL 데이터베이스에서 응용 프로그램 사용자의 자격 증명 교체 일정을 설정하십시오.**

**D. 애플리케이션 사용자의 RDS for MySQL 데이터베이스에서 자격 증명을 생성하고 자격 증명을 AWS Systems Manager Parameter Store에 저장합니다. Parameter Store에서 데이터베이스 자격 증명을 로드하도록 응용 프로그램을 구성하십시오. Parameter Store를 사용하여 RDS for MySQL 데이터베이스에서 응용 프로그램 사용자의 자격 증명 교체 일정을 설정하십시오.**

# QUESTION NO: 390

### 회사는 기가 바이트의 csv 파일에서 작동하고 수 개월의 데이터를 나타내는 레거시(기존) 온-프레미스 분석 응용 프로그램을 사용합니다. 레거시 응용 프로그램은 점점 커지는 csv 파일의 크기를 처리 할 수 없음. 다양한 데이터 원본에서 중앙 사내 스토리지 위치에 매일 새로운 CSV 파일이 추가됩니다.이 회사는 사용자가 AWS 분석 서비스를 학습하는 동안 기존 애플리케이션을 계속 지원하기를 원합니다. 이를 달성하기 위해 솔루션 아키텍트는 모든 csv 파일의 동기화 된 사본 두 개를 온 프레미스와 Amazon S3에서 유지 관리하려고합니다. (솔루션 설계자는 사내 및 Amazon S3에 있는 모든 csv 파일의 동기화된 복사본 2개를 유지하려고 합니다.)
솔루션 아키텍트는 어떤 솔루션을 추천해야 합니까?

**A. AWS DataSync 온 프레미스를 배포합니다. 회사의 온-프레미스 스토리지와 회사의 S3 버킷간에 csv 파일을 지속적으로 복제하도록 DataSync 구성
B. 온 프레미스 파일 게이트웨이 배포 csv 파일을 파일 게이트웨이에 쓰도록 데이터 소스 구성 레거시 분석 애플리케이션을 파일 게이트웨이로 지정 파일 게이트웨이는 csv 파일을 Amazon S3에 복제해야 합니다.
C. 온-프레미스 볼륨 게이트웨이를 배포합니다. csv 파일을 볼륨 게이트웨이에 쓰도록 데이터 소스를 구성하십시오. 레거시 분석 응용 프로그램을 볼륨 게이트웨이를 가리킵니다. 볼륨 게이트웨이는 데이터를 Amazon S3에 복제해야 합니다.
D. AWS DataSync 온 프레미스 배포 온 프레미스와 Amazon Elastic File System (Amazon EFS)간에 csv 파일을 지속적으로 복제하도록 DataSync를 구성합니다. Amazon EFS에서 회사의 S3 버킷으로 복제 할 수 있습니다.**

# QUESTION NO: 293

회사에는 파일 공유에 저장된 데이터에 액세스해야하는 여러 비즈니스 시스템이 있습니다.
비즈니스 시스템은 SMB (Server Message Block) 프로토콜을 사용하여 파일 공유에 액세스합니다. 파일 공유 솔루션은 회사의 기존 온 프레미스 환경과 AWS 모두에서 액세스 할 수 있어야 합니다.
비즈니스 요구 사항을 수정하는 서비스는 무엇입니까? (2 개 선택)

A. Amazon EBS

B. Amazon EFS

C. Windows 용 Amazon FSx

D. 아마존 S3

E. AWS Storage Gateway 파일 게이트웨이

# QUESTION NO: 307

솔루션 아키텍트는 직원과 파트너가 파일을 교환 할 수 있도록 온-프레미스 솔루션에 대한 완전 관리 형 대체를 제공해야 합니다. 온-프레미스 시스템, 원격 직원 및 외부 파트너에서 연결하는 직원이 솔루션에 쉽게 액세스 할 수 있어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Transfer for SFTP를 사용하여 Amazon S3 안팎으로 파일 전송

B. 로컬 스토리지 및 대규모 데이터 전송에 AWS Snowball Edge 사용

C. Amazon FSx를 사용하여 파일을 저장하고 전송하여 원격으로 사용할 수 있도록 합니다.

D. AWS Storage Gateway를 사용하여 파일을 저장하고 Amazon S3에 전송할 볼륨 게이트웨이를 생성합니다.

# QUESTION NO: 215

회사는 AWS Direct Connect 링크를 사용하여 코 로케이션 시설에서 us-east-1 리전의 Amazon S3 버킷으로 1PB의 데이터를 복사했습니다. 회사는 이제 us-west-2 리전의 다른 S3 버킷으로 데이터를 복사하려고 합니다. 코 로케이션 시설에서는 AWS Snowball을 사용할 수 없습니다.
이를 위해 솔루션 아키텍트는 무엇을 추천해야 합니까?

A. Snowball Edge 장치를 주문하여 한 지역에서 다른 지역으로 데이터를 복사하십시오.

B. S3 콘솔을 사용하여 소스 S3 버킷에서 대상 S3 버킷으로 내용을 전송합니다.

C. aws S3 sync 명령을 사용하여 소스 버킷에서 대상 버킷으로 데이터를 복사하십시오.

D. 교차 리전 복제 구성을 추가하여 다른 리전에 구성을 추가하여 다른 리전의 S3 버킷에 객체를 복사합니다.
